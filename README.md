# *ğŸ¯ Objectif*
Construire un modÃ¨le de machine learning (Random Forest Regressor) pour prÃ©dire les frais mÃ©dicaux en fonction de caractÃ©ristiques personnelles (Ã¢ge, IMC, tabagisme, etc.), afin dâ€™aider les compagnies dâ€™assurance Ã  mieux Ã©valuer les risques et fixer les tarifs.

# *ğŸ“Š DonnÃ©es*

* Source : Kaggle (harishkumardatalab/medical-insurance-price-prediction)
  
* Taille : 2 700 lignes, 7 colonnes
  
* Variables :
   * age : Ã‚ge
   * sex : Sexe
   * bmi : Indice de masse corporelle
   * children : Nombre dâ€™enfants
   * smoker : Tabagisme (oui/non)
   * region : RÃ©gion
   * charges : Frais mÃ©dicaux (cible)
     
# *ğŸ§¹ PrÃ©traitement*

* VÃ©rification des valeurs manquantes et aberrantes
  
* Visualisations : scatter plots, boxplots, camemberts
  
* Encodage :
    * smoker et sex â†’ boolÃ©ens
    * region â†’ renommÃ©e en franÃ§ais (southwest â†’ Nord, etc.)
    * SÃ©paration des donnÃ©es en X (features) et y (target)
      
# *ğŸ§  ModÃ©lisation*      
      
* Pipeline avec :
  * StandardScaler pour les variables numÃ©riques
  * OneHotEncoder pour les variables catÃ©gorielles
  * RandomForestRegressor comme modÃ¨le
* Optimisation des hyperparamÃ¨tres avec GridSearchCV :
  * n_estimators, max_depth, min_samples_split, min_samples_leaf

# *ğŸ“ˆ Ã‰valuation*

* Meilleurs paramÃ¨tres affichÃ©s
* MÃ©triques :
    * RMSE (Root Mean Squared Error)
    * RÂ² (coefficient de dÃ©termination)
    * MAPE (Mean Absolute Percentage Error)
* Visualisation des rÃ©sidus avec Yellowbrick

# *ğŸ’¾ Sauvegarde & PrÃ©diction*

* Le modÃ¨le est sauvegardÃ© avec joblib
* Une campagne de test est crÃ©Ã©e pour prÃ©dire les frais dâ€™un profil fictif :

| age | sex   | bmi  | children | smoker | region |
|-----|-------|------|----------|--------|--------|
| 24  | False | 23   | 2        | True   | Nord   |



